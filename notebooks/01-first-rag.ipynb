{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec(\"ace\"):\n",
    "    !pip install -qqq git+https://github.com/xtreamsrl/ace-of-splades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ace_of_splades.data import get_movies_dataset\n",
    "\n",
    "movies = get_movies_dataset(local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "\n",
    "uri = f\"{data_path}/movies_embeddings\"\n",
    "db = lancedb.connect(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_table = db.create_table(\"movies\", movies, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records(\n",
    "        query, *, encoder=encoder, db_table=movies_table, max_results=10\n",
    "):\n",
    "    query_vector = encoder.encode(query).tolist()\n",
    "    return db_table.search(\n",
    "        query_vector\n",
    "    ).limit(10).select(\n",
    "        ['release_year', 'title', 'origin', 'director', 'cast', 'genre', 'plot', '_distance']\n",
    "    ).to_list()\n",
    "\n",
    "\n",
    "question = \"What should I see tonight? I love Sci-Fi movies but I have seen most of the classics, such as Star Wars.\"\n",
    "\n",
    "docs = get_records(question, max_results=5)\n",
    "results = [doc for doc in docs]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEEK_SYSTEM = \"\"\"\n",
    "  You are a DVD record store assistant and your goal is to recommed the user with a good movie to watch.\n",
    "\n",
    "  You are a movie expert and a real geek: you love sci-fi movies and tend to get excited when you talk about them.\n",
    "  Nevertheless, no matter what, you always want to make your customers happy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "  Here are some suggested movies (ranked by relevance) to help you with your choice.\n",
    "  {context}\n",
    "\n",
    "  Use these suggestions to answer this question:\n",
    "  {question}\n",
    "\"\"\"\n",
    "\n",
    "context_template = \"\"\"\n",
    "Title: {title}\n",
    "Release date: {release_year}\n",
    "Director: {director}\n",
    "Cast: {cast}\n",
    "Genre: {genre}\n",
    "Overview: {plot}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_records_into_context(records, *, template):\n",
    "    return \"\".join(\n",
    "        context_template.format(\n",
    "            title=rec[\"title\"],\n",
    "            release_year=rec[\"release_year\"],\n",
    "            director=rec[\"director\"],\n",
    "            cast=rec[\"cast\"],\n",
    "            genre=rec[\"genre\"],\n",
    "            plot=rec[\"plot\"],\n",
    "        )\n",
    "        for rec in results\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "\n",
    "def ask(\n",
    "        question,\n",
    "        *,\n",
    "        max_results=10,\n",
    "        system=GEEK_SYSTEM,\n",
    "        prompt_template=prompt_template,\n",
    "        context_template=context_template,\n",
    "        db_table=movies_table,\n",
    "        verbose=False\n",
    "):\n",
    "    records = get_records(\n",
    "        query=question, max_results=max_results, db_table=movies_table\n",
    "    )\n",
    "    context = format_records_into_context(records, template=context_template)\n",
    "\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    answer = chat_completion\n",
    "    if verbose:\n",
    "        print(answer.choices[0].message.content)\n",
    "        print(context)\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "answer = ask(question=question, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Let's Run Our First Evaluation Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define better the datasets for domain expert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Now that we have generated some questions to boostrap our evaluation process we must make our system reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = pl.read_csv(\"../data/eval_questions.csv\")\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = eval_dataset.with_columns(\n",
    "    pl.col(\"question\").map_elements(\n",
    "        lambda question: ask(question).choices[0].message.content,\n",
    "        return_dtype=pl.String\n",
    "    ).alias('rag_answer')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "PL_STR_LEN = 1500\n",
    "\n",
    "pl.Config.set_fmt_str_lengths(PL_STR_LEN)\n",
    "pl.Config.set_tbl_width_chars(PL_STR_LEN)\n",
    "\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Cool! Our movie expert replies to all the questions in our dataset; our work here is done! But... let's see what our **movie expert** would say about it.\n",
    "\n",
    "He's not accustomed to `polars`, so let's prepare a more convenient Excel for him!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Could we improve this Excel a little bit later\n",
    "eval_dataset.write_excel(workbook=\"../data/eval_questions_answered.xlsx\",\n",
    "                         column_totals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Let's see what the domain expert voted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_expert_critiques = pl.read_excel(\n",
    "    source=\"../data/eval_questions_with_critiques.xlsx\",\n",
    "    sheet_name=\"Sheet1\",\n",
    ")\n",
    "domain_expert_critiques.with_columns(pl.col('Judgement').cast(pl.Categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_expert_critiques.select(\n",
    "    pl.col('Judgement').value_counts(sort=True, name=\"Count\")\n",
    ").unnest(\"Judgement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "There are a lot of failures (80%), so let's eye-balling the critiques from the domain expert and cluster them in groups. Possible groups could be:\n",
    "- missing context: frequently, domain experts said that the model replied saying that it doesn't have the movie in the list\n",
    "- The system always gives the same suggestion (\"Welcome to the Space Show\")\n",
    "- It doesn't manage corner cases, such as unrelated or toxic questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## The \"Easiest First\" Rule\n",
    "Don't panic! You don't need to rebuild all your RAG. Let's keep things simple before discussing complex considerations about restructuring your RAG architecture.\n",
    "\n",
    "The easiest things to look at are prompts and system messages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GEEK_SYSTEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Let's quickly iterate through our system message to check if we could have a better response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\" You are a movie expert and your goal is to recommed the user with a good movie to watch.\n",
    "\n",
    "RULES: \n",
    "- You should reply to questions about: movies plots or synopsys, movies metadata (release date, cast, or director), provide plots summary;\n",
    "- For every questions outside the scope please reply politely that you're not able to provide a response and desbribe briefly your scope;\n",
    "- Don't mention that you have a list of films as a context. This should be transparent to the user\n",
    "- If you don't have the movie in your context reply that you don't know how to reply\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = eval_dataset.with_columns(\n",
    "    pl.col(\"question\").map_elements(\n",
    "        lambda question: ask(question, system=SYSTEM_MESSAGE).choices[0].message.content,\n",
    "        return_dtype=pl.String\n",
    "    ).alias('rag_answer')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
